{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25ad8df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b61766",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(__file__).parent.parent.parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30d8092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIG ===\n",
    "MODEL_PATH = BASE_DIR / \"models\" / \"wgisd-grape-cluster-detection-v1.pt\"   # tu modelo guardado\n",
    "IMAGE_PATH = BASE_DIR / \"data\" / \"yolo\" / \"images\" / \"val\" / \"CDY_2015.jpeg\"            # imagen que quieres predecir\n",
    "CONF_THRESH = 0.25                               # mínimo confidence para mostrar detección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a03fd71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo\n",
    "model = YOLO(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "766df016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/emersonmt/Documents/PUCP/2025-2/IA-aplicada/TA/transfer_learning/wgisd-yolo/images/val/CDY_2015.jpeg: 448x640 24 uva_bboxs, 26.8ms\n",
      "Speed: 5.3ms preprocess, 26.8ms inference, 6.1ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    }
   ],
   "source": [
    "# Realizar predicción\n",
    "results = model.predict(source=IMAGE_PATH, conf=CONF_THRESH)\n",
    "\n",
    "# Tomar la primera predicción (solo una imagen)\n",
    "result = results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36b22e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'uva_bbox'}\n",
      "obb: None\n",
      "orig_img: array([[[ 24,  41,  27],\n",
      "        [ 24,  41,  27],\n",
      "        [ 24,  41,  27],\n",
      "        ...,\n",
      "        [194, 186, 149],\n",
      "        [190, 185, 154],\n",
      "        [184, 177, 150]],\n",
      "\n",
      "       [[ 25,  42,  28],\n",
      "        [ 24,  41,  27],\n",
      "        [ 24,  41,  27],\n",
      "        ...,\n",
      "        [186, 177, 143],\n",
      "        [195, 187, 157],\n",
      "        [190, 183, 156]],\n",
      "\n",
      "       [[ 27,  42,  28],\n",
      "        [ 26,  41,  27],\n",
      "        [ 26,  41,  27],\n",
      "        ...,\n",
      "        [184, 173, 141],\n",
      "        [197, 189, 160],\n",
      "        [193, 186, 159]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 75, 116,  95],\n",
      "        [ 88, 127, 119],\n",
      "        [ 96, 134, 146],\n",
      "        ...,\n",
      "        [233, 241, 241],\n",
      "        [231, 238, 241],\n",
      "        [223, 230, 233]],\n",
      "\n",
      "       [[115, 140, 150],\n",
      "        [ 88, 113, 129],\n",
      "        [ 57,  85, 115],\n",
      "        ...,\n",
      "        [233, 241, 241],\n",
      "        [231, 239, 239],\n",
      "        [227, 235, 235]],\n",
      "\n",
      "       [[ 78,  96, 103],\n",
      "        [ 46,  64,  75],\n",
      "        [ 37,  62,  78],\n",
      "        ...,\n",
      "        [233, 241, 240],\n",
      "        [229, 237, 237],\n",
      "        [231, 239, 239]]], shape=(1365, 2048, 3), dtype=uint8)\n",
      "orig_shape: (1365, 2048)\n",
      "path: '/home/emersonmt/Documents/PUCP/2025-2/IA-aplicada/TA/transfer_learning/wgisd-yolo/images/val/CDY_2015.jpeg'\n",
      "probs: None\n",
      "save_dir: '/home/emersonmt/Documents/PUCP/2025-2/IA-aplicada/TA/transfer_learning/runs/detect/predict'\n",
      "speed: {'preprocess': 5.339522999975088, 'inference': 26.842881999982637, 'postprocess': 6.1015200000156256}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03010174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer la imagen original con OpenCV\n",
    "img = cv2.imread(IMAGE_PATH)\n",
    "\n",
    "# Dibujar los bounding boxes y etiquetas\n",
    "for box, score in zip(result.boxes.xyxy, result.boxes.conf):\n",
    "    x1, y1, x2, y2 = map(int, box)\n",
    "    conf = float(score)\n",
    "    label = f\"uva {conf:.2f}\"\n",
    "    \n",
    "    # Dibujar rectángulo\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    # Poner texto\n",
    "    cv2.putText(img, label, (x1, y1 - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "# Mostrar imagen con bounding boxes\n",
    "cv2.imshow(\"Detecciones de Uvas\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Si quieres guardar la imagen con bb\n",
    "cv2.imwrite(\"resultado_bb.jpeg\", img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia-aplicada-venv311 (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
